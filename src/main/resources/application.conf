extractor {
  zookeeper {
    url = "localhost:2181"
    session.timeout = 12000
    connection.timeout = 60000
    security.enabled = false
    extractor.znode.path = "/cloudwick/extractor"

    # Additional Zookeeper Configurations
    configurations = [
      # { name = "propname", value = "propvalue" }
    ]
  }
  kafka {
    # List of host:port pairs of Kafka brokers, provide at-least two to three brokers in case one
    # broker goes down the producer will still be able to connect to the cluster.
    brokers.list = [
      "localhost:9092"
    ]

    # Additional Kafka Configuration
    configurations = [
      {name = "linger.ms", value = "10"}
    ]

    # Topic configuration
    auto.offset.reset = "latest"
    #possible values
    source.name = "logtrust"
    # Kafka serializers
    key.serializer = "org.apache.kafka.common.serialization.StringSerializer"
    value.serializer = "org.apache.kafka.common.serialization.StringSerializer"

    # Kafka Deserializers
    key.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
    value.deserializer = "org.apache.kafka.common.serialization.StringDeserializer"
  }
  spark.app.name = kafka-extractor
  spark.app.clustermode = local
  store.location = /Users/ravi/data/Pout/Logs
}